# CosyVoice LLM + Flow Joint LoRA Finetune

<p align="center">
  <a href="#features">Features</a> â€¢
  <a href="#quick-start">Quick Start</a> â€¢
  <a href="#usage">Usage</a> â€¢
  <a href="#configuration">Configuration</a> â€¢
  <a href="#faq">FAQ</a>
</p>

CosyVoice **LLM + Flow è”åˆå¾®è°ƒ**å·¥å…·ï¼Œæ”¯æŒå°‘é‡æ•°æ®ï¼ˆ10-50æ¡ï¼‰å¿«é€Ÿå¾®è°ƒï¼Œå®ç°**æ— éœ€å‚è€ƒéŸ³é¢‘**çš„æ¨ç†ã€‚

## Features

- ğŸ¯ **è”åˆè®­ç»ƒ**ï¼šåŒæ—¶å¾®è°ƒ LLM å’Œ Flowï¼Œå­¦ä¹ éŸ³è‰² + éŸµå¾‹é£æ ¼
- ğŸš€ **æ—  Prompt æ¨ç†**ï¼šè®­ç»ƒåæ¨ç†æ— éœ€å‚è€ƒéŸ³é¢‘ï¼Œå½»åº•è§£å†³è¯­ä¹‰æ³„æ¼é—®é¢˜
- ğŸ“¦ **å°‘é‡æ•°æ®**ï¼š10-50 æ¡éŸ³é¢‘å³å¯å¾®è°ƒå‡ºé«˜è´¨é‡éŸ³è‰²
- âš¡ **LoRA é«˜æ•ˆè®­ç»ƒ**ï¼šä»…è®­ç»ƒå°‘é‡å‚æ•°ï¼Œ8GB æ˜¾å­˜å¯ç”¨
- ğŸ”§ **é˜²è¿‡æ‹Ÿåˆæœºåˆ¶**ï¼šå†…ç½® LLM loss é˜ˆå€¼ï¼Œè‡ªåŠ¨é˜²æ­¢è¿‡æ‹Ÿåˆ

## Why Joint Training?

ä¼ ç»Ÿ Zero-Shot æ–¹æ¡ˆåªå¾®è°ƒ Flowï¼Œéœ€è¦å‚è€ƒéŸ³é¢‘æ‰èƒ½æ¨ç†ï¼Œä¸”å­˜åœ¨**è¯­ä¹‰æ³„æ¼**é—®é¢˜ï¼ˆè¾“å‡ºå¼€å¤´åŒ…å«å‚è€ƒéŸ³é¢‘ç»“å°¾å†…å®¹ï¼‰ã€‚

**è”åˆè®­ç»ƒæ–¹æ¡ˆ**åŒæ—¶å¾®è°ƒ LLM å’Œ Flowï¼š
- LLM å­¦ä¹ ç›®æ ‡è¯´è¯äººçš„éŸµå¾‹ã€èŠ‚å¥ã€åŸè¯µé£æ ¼
- Flow å­¦ä¹ ç›®æ ‡è¯´è¯äººçš„éŸ³è‰²ç‰¹å¾
- æ¨ç†æ—¶æ— éœ€å‚è€ƒéŸ³é¢‘ï¼Œä»æ ¹æœ¬ä¸Šè§£å†³è¯­ä¹‰æ³„æ¼

## Project Structure

```
cosyvoice_flow_finetune/
â”œâ”€â”€ config.py              # ç»Ÿä¸€é…ç½®æ–‡ä»¶
â”œâ”€â”€ train_joint.py         # è”åˆè®­ç»ƒè„šæœ¬
â”œâ”€â”€ inference_joint.py     # æ—  Prompt æ¨ç†è„šæœ¬
â”œâ”€â”€ prepare_joint_data.py  # æ•°æ®å‡†å¤‡è„šæœ¬
â”œâ”€â”€ llm_flow_model.py      # è”åˆæ¨¡å‹å®šä¹‰
â”œâ”€â”€ merge_joint_weights.py # æƒé‡åˆå¹¶å·¥å…·
â”œâ”€â”€ dataset.py             # æ•°æ®é›†åŠ è½½
â”œâ”€â”€ lora.py                # LoRA å®ç°
â”œâ”€â”€ utils.py               # å·¥å…·å‡½æ•°
â”œâ”€â”€ cosyvoice/             # CosyVoice æ ¸å¿ƒä»£ç ï¼ˆå·²é›†æˆï¼‰
â”œâ”€â”€ matcha/                # Matcha-TTS æ ¸å¿ƒä»£ç ï¼ˆå·²é›†æˆï¼‰
â”œâ”€â”€ data/                  # è®­ç»ƒæ•°æ®ç›®å½•ï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰
â””â”€â”€ output/                # è¾“å‡ºç›®å½•ï¼ˆæ¨¡å‹æƒé‡ï¼‰
```

## Quick Start

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/YOUR_USERNAME/cosyvoice_flow_finetune.git
cd cosyvoice_flow_finetune

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### 2. ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹

ä»ä»¥ä¸‹åœ°å€ä¸‹è½½ CosyVoice-300M æ¨¡å‹ï¼š

| æ¥æº | é“¾æ¥ |
|-----|------|
| ModelScope | https://www.modelscope.cn/models/iic/CosyVoice-300M |
| HuggingFace | https://huggingface.co/FunAudioLLM/CosyVoice-300M |

**å¿«é€Ÿä¸‹è½½ï¼ˆHuggingFaceï¼‰**ï¼š
```bash
pip install huggingface_hub
python -c "from huggingface_hub import snapshot_download; snapshot_download('FunAudioLLM/CosyVoice-300M', local_dir='./pretrained_models/CosyVoice-300M')"
```

ä¸‹è½½åæ”¾ç½®åˆ°ä¸Šä¸€çº§ç›®å½•ï¼š
```
pretrained_models/CosyVoice-300M/
â”œâ”€â”€ flow.pt              # Flow æ¨¡å‹æƒé‡
â”œâ”€â”€ hift.pt              # HiFi-GAN å£°ç å™¨
â”œâ”€â”€ llm.pt               # LLM æ¨¡å‹
â”œâ”€â”€ campplus.onnx        # è¯´è¯äººç¼–ç å™¨
â”œâ”€â”€ speech_tokenizer_v1.onnx  # è¯­éŸ³åˆ†è¯å™¨
â””â”€â”€ cosyvoice.yaml       # é…ç½®æ–‡ä»¶
```

### 3. å‡†å¤‡è®­ç»ƒæ•°æ®

åœ¨ä¸Šä¸€çº§ç›®å½•åˆ›å»º `data_preparation/short_raw_data/` ç›®å½•ï¼Œæ”¾å…¥éŸ³é¢‘å’Œå¯¹åº”æ–‡æœ¬ï¼š

```
data_preparation/short_raw_data/
â”œâ”€â”€ 001.wav
â”œâ”€â”€ 001.txt      # åŒ…å« 001.wav çš„æ–‡æœ¬å†…å®¹
â”œâ”€â”€ 002.wav
â”œâ”€â”€ 002.txt
â””â”€â”€ ...
```

**æ•°æ®è¦æ±‚**ï¼š
- éŸ³é¢‘æ ¼å¼ï¼šWAVï¼ˆæ¨èï¼‰æˆ– MP3
- éŸ³é¢‘æ—¶é•¿ï¼š30ç§’ä»¥å†…ï¼ˆå»ºè®® 2-5 ç§’ï¼‰
- é‡‡æ ·ç‡ï¼šä»»æ„ï¼ˆä¼šè‡ªåŠ¨é‡é‡‡æ ·ï¼‰
- æ¨èæ•°æ®é‡ï¼š20-50 æ¡
- **é‡è¦**ï¼šæ–‡æœ¬ä¸éŸ³é¢‘å†…å®¹å¿…é¡»ç²¾ç¡®å¯¹åº”

### 4. ç”Ÿæˆè®­ç»ƒæ•°æ®

```bash
python prepare_joint_data.py
```

è¿™ä¼šåœ¨ `data/` ç›®å½•ä¸‹ç”Ÿæˆ parquet æ ¼å¼çš„è®­ç»ƒæ•°æ®ã€‚

### 5. å¼€å§‹è®­ç»ƒ

```bash
# è”åˆè®­ç»ƒï¼ˆæ¨èï¼‰
python train_joint.py

# ä» checkpoint æ¢å¤
python train_joint.py --resume output/joint_joint_last.ckpt
```

**è®­ç»ƒä¼šåœ¨ä»¥ä¸‹æ¡ä»¶æ—¶è‡ªåŠ¨åœæ­¢**ï¼š
- LLM loss è¾¾åˆ° 1.5ï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰
- Flow loss è¾¾åˆ° 0.3
- è¿ç»­ 10 ä¸ª epoch æ— æ”¹å–„ï¼ˆæ—©åœï¼‰

### 6. æ¨ç†æµ‹è¯•

```bash
# æ—  Prompt æ¨ç†ï¼ˆæ¨èï¼‰
python inference_joint.py \
    --llm output/llm_merged_joint.pt \
    --flow output/flow_merged_joint.pt \
    --text "è¦åˆæˆçš„æ–‡æœ¬"

# æŒ‡å®šè¾“å‡ºè·¯å¾„
python inference_joint.py \
    --llm output/llm_merged_joint.pt \
    --flow output/flow_merged_joint.pt \
    --text "åºŠå‰æ˜æœˆå…‰ï¼Œç–‘æ˜¯åœ°ä¸Šéœœ" \
    --output output/result.wav
```

## Usage

### è®­ç»ƒæ¨¡å¼

```bash
# è”åˆè®­ç»ƒï¼ˆæ¨èï¼ŒåŒæ—¶å­¦ä¹ éŸµå¾‹+éŸ³è‰²ï¼‰
python train_joint.py --mode joint

# åªè®­ç»ƒ LLMï¼ˆå­¦ä¹ éŸµå¾‹é£æ ¼ï¼‰
python train_joint.py --mode llm_only

# åªè®­ç»ƒ Flowï¼ˆå­¦ä¹ éŸ³è‰²ï¼‰
python train_joint.py --mode flow_only
```

### æ‰‹åŠ¨åˆå¹¶æƒé‡

å¦‚æœè®­ç»ƒä¸­æ–­ï¼Œå¯ä»¥æ‰‹åŠ¨åˆå¹¶ checkpoint ä¸­çš„ LoRA æƒé‡ï¼š

```bash
python merge_joint_weights.py --ckpt output/joint_joint_last.ckpt
```

### æ¨ç†å‚æ•°

```bash
python inference_joint.py \
    --llm output/llm_merged_joint.pt \    # LLM æƒé‡è·¯å¾„
    --flow output/flow_merged_joint.pt \  # Flow æƒé‡è·¯å¾„
    --text "è¦åˆæˆçš„æ–‡æœ¬" \                # åˆæˆæ–‡æœ¬
    --output output/result.wav \          # è¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼‰
    --speed 1.0                           # è¯­é€Ÿè°ƒèŠ‚ï¼ˆå¯é€‰ï¼‰
```

## Configuration

æ‰€æœ‰é…ç½®éƒ½åœ¨ `config.py` ä¸­ã€‚

### è”åˆè®­ç»ƒå‚æ•°

```python
JOINT_TRAINING_CONFIG = {
    'training_mode': 'joint',      # è®­ç»ƒæ¨¡å¼

    # Loss æƒé‡
    'llm_loss_weight': 2.0,        # LLM loss æƒé‡ï¼ˆå¼ºåŒ–éŸµå¾‹å­¦ä¹ ï¼‰
    'flow_loss_weight': 1.0,       # Flow loss æƒé‡

    # LLM LoRA é…ç½®
    'llm_lora': {
        'lora_r': 8,               # LoRA ç§©
        'lora_alpha': 16,          # ç¼©æ”¾å› å­
        'lora_dropout': 0.15,      # Dropoutï¼ˆé˜²è¿‡æ‹Ÿåˆï¼‰
    },

    # Flow LoRA é…ç½®
    'flow_lora': {
        'lora_r': 16,
        'lora_alpha': 32,
        'lora_dropout': 0.05,
    },

    # è®­ç»ƒå‚æ•°
    'learning_rate': 2e-4,
    'max_epochs': 100,
    'batch_size': 1,
    'accumulate_grad_batches': 16,
}
```

### Loss é˜ˆå€¼è¯´æ˜

| æŒ‡æ ‡ | æœ€ä½³èŒƒå›´ | è¯´æ˜ |
|-----|---------|------|
| LLM loss | 1.5 ~ 2.5 | è¿‡ä½ä¼šå¯¼è‡´è¿‡æ‹Ÿåˆï¼ˆè‡ªè¯´è‡ªè¯ï¼‰ |
| Flow loss | 0.3 ~ 0.5 | è¶Šä½éŸ³è‰²è¶Šæ¸…æ™° |

## Training Tips

### æ˜¾å­˜ä¼˜åŒ–

8GB æ˜¾å­˜æ¨èé…ç½®ï¼ˆå·²åœ¨ config.py ä¸­è®¾ç½®ï¼‰ï¼š
- `batch_size`: 1
- `accumulate_grad_batches`: 16
- `max_feat_len`: 250ï¼ˆçº¦ 1.7 ç§’ï¼‰
- `lora_r`: 8ï¼ˆLLMï¼‰/ 16ï¼ˆFlowï¼‰

### è¿‡æ‹Ÿåˆå¤„ç†

å¦‚æœå‡ºç°"è‡ªè¯´è‡ªè¯"ç°è±¡ï¼ˆè¯´å®Œæ–‡æœ¬åç»§ç»­ç”Ÿæˆï¼‰ï¼š
1. æ£€æŸ¥ LLM lossï¼Œå¦‚æœ < 1.5 è¯´æ˜è¿‡æ‹Ÿåˆ
2. ä½¿ç”¨æ›´æ—©çš„ checkpointï¼ˆLLM loss åœ¨ 1.5-2.0 çš„ç‰ˆæœ¬ï¼‰
3. å¢å¤§ `llm_lora.lora_dropout`

### è®­ç»ƒç›‘æ§

```bash
tensorboard --logdir output/joint_logs
```

## FAQ

### Q: è¾“å‡ºéŸ³é¢‘"è‡ªè¯´è‡ªè¯"ï¼Œè¯´å®Œæ–‡æœ¬åè¿˜åœ¨ç»§ç»­
**A**: LLM è¿‡æ‹Ÿåˆã€‚ä½¿ç”¨ LLM loss åœ¨ 1.5-2.0 èŒƒå›´å†…çš„ checkpointï¼Œæˆ–å¢å¤§ dropoutã€‚

### Q: éŸ³è‰²ä¸åƒç›®æ ‡è¯´è¯äºº
**A**: Flow è®­ç»ƒä¸è¶³ã€‚å¯ä»¥å•ç‹¬ç”¨ `--mode flow_only` ç»§ç»­è®­ç»ƒ Flowã€‚

### Q: éŸµå¾‹å¤ªå¹³æ·¡ï¼Œæ²¡æœ‰ç‰¹è‰²
**A**: LLM è®­ç»ƒä¸è¶³ã€‚æ£€æŸ¥ LLM loss æ˜¯å¦è¿˜åœ¨ 2.5 ä»¥ä¸Šï¼Œå¯é€‚å½“å»¶é•¿è®­ç»ƒã€‚

### Q: CUDA å†…å­˜ä¸è¶³
**A**:
1. ç¡®ä¿ `batch_size` ä¸º 1
2. å‡å° `max_feat_len`ï¼ˆconfig.pyï¼‰
3. å‡å° `lora_r`

### Q: æ‰¾ä¸åˆ°æ¨¡å—
**A**: ç¡®ä¿ä» `cosyvoice_flow_finetune` ç›®å½•è¿è¡Œè„šæœ¬ï¼Œæˆ–æ£€æŸ¥ `config.py` ä¸­çš„è·¯å¾„ã€‚

## Model Architecture

```
æ–‡æœ¬ â†’ [LLM + LoRA] â†’ speech_tokens â†’ [Flow + LoRA] â†’ mel â†’ HiFi-GAN â†’ éŸ³é¢‘
         â†‘                                â†‘
      å­¦ä¹ éŸµå¾‹                          å­¦ä¹ éŸ³è‰²
```

## Acknowledgments

- [CosyVoice](https://github.com/FunAudioLLM/CosyVoice) - é˜¿é‡Œå·´å·´ FunAudioLLM å›¢é˜Ÿ
- [Matcha-TTS](https://github.com/shivammehta25/Matcha-TTS) - Flow Matching TTS

## License

æœ¬é¡¹ç›®éµå¾ª [CosyVoice](https://github.com/FunAudioLLM/CosyVoice) çš„å¼€æºåè®®ã€‚
